__global__ void flash_attention_kernel(float *query, float *key, float *value, size_t N, size_t d) {

}

void flash_attention_gpu(float *query, float *key, float *value, size_t N, size_t d) {
}
